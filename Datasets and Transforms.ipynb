{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps \n",
    "\n",
    "\n",
    "1. Create a function that takes a **tuple of two images** and returns a tuple of the same two cropped (or, equivalently, a patch from the) images, where the cropped images are of the same **randomly determined location**.\n",
    "\n",
    "2. Verify that this was implemented correctly by visualizing the output images as in the previous module.  Create a class that inherits from **Dataset** to handle the NIfTI files. Implement the following methods:\n",
    "\n",
    "```\n",
    "  __init__\n",
    "  __len__\n",
    "  __getitem__\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "Please show evidence that the two classes/functions work as expected. For example, output an example from your Dataset class and plot slices from the output image pair (showing that they are from the same subject and align in space). Similarly, show that the crop function actually crops the image by printing the size of the output images and plotting an image pair output by this function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "* https://liveproject.manning.com/module/103_3_1/3d-medical-image-analysis-with-pytorch/2--datasets-and-transforms/2-1--datasets-and-transforms?\n",
    "* https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "* https://livebook.manning.com/book/deep-learning-with-pytorch/chapter-10/v-13/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "import nibabel as nib\n",
    "from fnmatch import fnmatch\n",
    "import os,re\n",
    "\n",
    "def load_mr_image(subj, ttype):\n",
    "    suff = ttype.upper()\n",
    "    if ttype == 't2': \n",
    "        suff = f'{suff}_reg'\n",
    "    return nib.load(f'./data/small/{ttype}/{subj}-{suff}_fcm.nii.gz')\n",
    "\n",
    "def path_to_subj(path):\n",
    "    m = re.search(r\"(IXI\\d{3}-HH-\\d{4})\", path)\n",
    "    return m.group(1)\n",
    "\n",
    "class NiftiDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Extract images from the source (t1) and target (t2) directories\n",
    "     \n",
    "    Args:\n",
    "        source: path to load source from\n",
    "        target: path to load target from \n",
    "        transforms: trransforms to apply to both\n",
    "    \"\"\"\n",
    "    def __init__(self, source_dir, target_dir, transform=None):\n",
    "        \n",
    "        # look in the directory and collect pairs of items. \n",
    "        t1_files = os.listdir(source_dir)\n",
    "        t2_files = os.listdir(target_dir)\n",
    "\n",
    "        self.subj_list = [ path_to_subj(e) for e in t1_files if fnmatch(e, r'*T1_fcm.nii.gz') ]        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.subj_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        t1 = load_mr_image(self.subj_list[idx], \"t1\")\n",
    "        t2 = load_mr_image(self.subj_list[idx], \"t2\")\n",
    "        # TODO: should we automatically tranform np arrays to tensors? \n",
    "        sample = {'source': t1, 'target': t2}\n",
    "        \n",
    "        #could I run the transform on each individually?  Do I need my transform function to handle both?\n",
    "        #technically the requirements call for a transform that works on a pair of images. \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "        \n",
    "\n",
    "#transform\n",
    "# https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#transforms\n",
    "class RandomCrop3D:\n",
    "    \"\"\"Randomly crop randomly a 3D patch from images in an image pair.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, cube patch\n",
    "            is made.\n",
    "    \"\"\" \n",
    "\n",
    "    \n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int,tuple))\n",
    "        if isinstance(output_size,int):\n",
    "            self.output_size = (output_size, output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size)==3\n",
    "            self.output_size = output_size\n",
    "\n",
    "    @staticmethod\n",
    "    def crop(image, output_size):\n",
    "        \n",
    "         #TODO: did I get the indexes right here? Might be L x H X W\n",
    "        h,w,l = image.shape[:3]\n",
    "        new_h, new_w, new_l = self.output_size\n",
    "        \n",
    "        assert new_h < h and new_w < w and new_l < l\n",
    "        \n",
    "        top   = np.random.randint(0, h - new_h)\n",
    "        left  = np.random.randint(0, w - new_w)\n",
    "        front = np.random.randint(0, l - new_l)\n",
    "        \n",
    "        image = image[top:top+new_h, left:left+new_w, front:front+new_l]\n",
    "        return image       \n",
    "            \n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        transformed = {}\n",
    "        for i in ['source', 'target']:\n",
    "            img_obj = getattr(sample,i)\n",
    "            setattr(transformed, i, RandomCrop3D.crop(img_obj, output_size))\n",
    "            \n",
    "        return transformed\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs is a tuple\n",
    "#dims is the size of the image you want to crop. \n",
    "\n",
    "def random_crop(imgs, dims):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IXI161-HH-2533\n",
      "IXI159-HH-1549\n"
     ]
    }
   ],
   "source": [
    "t2t = 'data/small/t2/IXI161-HH-2533-T2_reg_fcm.nii.gz'\n",
    "t1t = 'data/small/t1/IXI159-HH-1549-T1_fcm.nii.gz'\n",
    "print(path_to_subj(t2t))\n",
    "print(path_to_subj(t1t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl = NiftiDataset('./data/small/t1', './data/small/t2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IXI167-HH-1569',\n",
       " 'IXI161-HH-2533',\n",
       " 'IXI180-HH-1605',\n",
       " 'IXI128-HH-1470',\n",
       " 'IXI168-HH-1607',\n",
       " 'IXI162-HH-1548',\n",
       " 'IXI159-HH-1549',\n",
       " 'IXI127-HH-1451',\n",
       " 'IXI174-HH-1571',\n",
       " 'IXI131-HH-1527',\n",
       " 'IXI148-HH-1453',\n",
       " 'IXI102-HH-1416',\n",
       " 'IXI137-HH-1472',\n",
       " 'IXI176-HH-1604',\n",
       " 'IXI165-HH-1589',\n",
       " 'IXI132-HH-1415',\n",
       " 'IXI195-HH-1620',\n",
       " 'IXI150-HH-1550',\n",
       " 'IXI175-HH-1570',\n",
       " 'IXI126-HH-1437',\n",
       " 'IXI105-HH-1471',\n",
       " 'IXI163-HH-1621',\n",
       " 'IXI104-HH-1450',\n",
       " 'IXI160-HH-1637',\n",
       " 'IXI173-HH-1590',\n",
       " 'IXI146-HH-1389',\n",
       " 'IXI130-HH-1528',\n",
       " 'IXI136-HH-1452']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndl.subj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nibabel.nifti1.Nifti1Image at 0x7f050c1bfd30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ndl[4]\n",
    "s['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(ndl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
