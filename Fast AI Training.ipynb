{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastai 3D images\n",
    "\n",
    "\n",
    "### Resources\n",
    "\n",
    "* https://towardsdatascience.com/working-with-3d-data-fastai2-5e2baa09037e \n",
    "* https://www.kaggle.com/jhoward/some-dicom-gotchas-to-be-aware-of-fastai\n",
    "* https://forums.fast.ai/t/fastai-v2-has-a-medical-imaging-submodule/56117\n",
    "* https://towardsdatascience.com/deep-learning-with-magnetic-resonance-and-computed-tomography-images-e9f32273dcb5\n",
    "\n",
    "Note that Fastai defaults to DICOM and doesn't appear to support NIFTI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.all import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write a DataBlock. \n",
    "\n",
    "It will give you back a Dataset and DataLoader\n",
    "\n",
    "\n",
    "To build a DataBlock you need to give the library four things: \n",
    " \n",
    "* the types of your input/labels, and at least two functions: `get_items` and `splitter`. \n",
    "* You may also need to include `get_x` and `get_y` or a more generic list of getters that are applied to the results of get_items.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example DataBlock - won't run.\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks    = (ImageSequenceBlock, CategoryBlock),\n",
    "    get_items = SequenceGetItems('file', 'sequence_id', 'label'), \n",
    "    get_x     = lambda t : t[:-1],\n",
    "    get_y     = lambda t : t[-1],\n",
    "    splitter  = RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the definition of an ImageBlock in the fast.ai codebase.\n",
    "def ImageBlock(cls=PILImage):\n",
    "    \"A `TransformBlock` for images of `cls`\"\n",
    "    return TransformBlock(type_tfms=cls.create, batch_tfms=IntToFloatTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is the format of get_items? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.fast.ai/data.transforms.html#get_files\n",
    "files = get_files('./data/small/t1', extensions='.gz', recurse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('data/small/t1/IXI167-HH-1569-T1_fcm.nii.gz')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastcore.foundation.L"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the first link in the resource section:\n",
    "\n",
    "> remember from the DataBlock example above that get_x and get_y receive the output from get_items and should separate what is the input and what is the target. In this case, they are as simple as this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NiftiGetItems():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def __call__(self, source_dir):\n",
    "        \n",
    "        #TODO: could just take the parent directory\n",
    "        t1_files = os.listdir(source_dir)\n",
    "\n",
    "        subj_list = [ path_to_subj(e) for e in t1_files if fnmatch(e, r'*T1_fcm.nii.gz') ] \n",
    "        \n",
    "        out = [] \n",
    "        \n",
    "        for s in subj_list:\n",
    "            t1 = load_mr_image(s, \"t1\")\n",
    "            t2 = load_mr_image(s, \"t2\")           \n",
    "            out.append({'source': t1, 'target': t2})\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "#https://fastcore.fast.ai/transform#Transform\n",
    "class NiftiToTensor(Transform):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "#This class is only needed if you decide to make GetItems just return paths. \n",
    "def NiftiBlock():\n",
    "    return TransformBlock(item_tfms=NiftiToTensor(),\n",
    "                          #batch_tfms= crop or data augment here...\n",
    "                          #type_tfms= path to nifti obj. \n",
    "                         )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(\n",
    "    #blocks    = NiftiBlock(),\n",
    "    get_items = NiftiGetItems(),\n",
    "    get_x     = lambda t : t['source'], \n",
    "    get_y     = lambda t : t['target'],\n",
    "    #n_inp = how many inputs do you want to pass into the datablock / get_items, etc. \n",
    "    splitter  = RandomSplitter())\n",
    "\n",
    "#TODO: See above. \n",
    "# - crop is not happening. Fix this. \n",
    "# - not creating tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = dblock.datasets('./data/small/t1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#28) [(<nibabel.nifti1.Nifti1Image object at 0x7ffa7d2cd850>, <nibabel.nifti1.Nifti1Image object at 0x7ffa7d2cd520>),(<nibabel.nifti1.Nifti1Image object at 0x7ffa7d2cddf0>, <nibabel.nifti1.Nifti1Image object at 0x7ffa7d2b2a30>),(<nibabel.nifti1.Nifti1Image object at 0x7ffa7d2fb460>, <nibabel.nifti1.Nifti1Image object at 0x7ffa7d2b2820>),(<nibabel.nifti1.Nifti1Image object at 0x7ffa7d2b2eb0>, <nibabel.nifti1.Nifti1Image object at 0x7ffa7d2cdfd0>),(<nibabel.nifti1.Nifti1Image object at 0x7ffa7d2da0a0>, <nibabel.nifti1.Nifti1Image object at 0x7ffa7d2da580>),(<nibabel.nifti1.Nifti1Image object at 0x7ffa7d2da3d0>, <nibabel.nifti1.Nifti1Image object at 0x7ffa7d2da130>),(<nibabel.nifti1.Nifti1Image object at 0x7ffa7d2dae20>, <nibabel.nifti1.Nifti1Image object at 0x7ffa7d2de1c0>),(<nibabel.nifti1.Nifti1Image object at 0x7ffa7d2de040>, <nibabel.nifti1.Nifti1Image object at 0x7ffa7d2de250>),(<nibabel.nifti1.Nifti1Image object at 0x7ffa7d2de490>, <nibabel.nifti1.Nifti1Image object at 0x7ffa7d2dee50>),(<nibabel.nifti1.Nifti1Image object at 0x7ffa7d2e31f0>, <nibabel.nifti1.Nifti1Image object at 0x7ffa7d2e3070>)...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.data.core.Datasets"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<nibabel.nifti1.Nifti1Image at 0x7ffa7d2da280>,\n",
       " <nibabel.nifti1.Nifti1Image at 0x7ffa7d2f0100>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-v2",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
